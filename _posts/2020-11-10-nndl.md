---
layout: post
title:  notes on neural networks
---
# Notes on Neural Networks & Deep Learning
**⚠️NOTE: This is a work in progress. Idea is to keep a note of concepts I find useful & interesting while learning through various sources.**

[Part.1: Definitions & Terminology](#i.-definitions-&-terminology)
 - [The Neuron](#the-neuron)
 - [Learning Algorithm](#learning-algorithm)
 - [The Sigmoid Neuron](#the-sigmoid-neuron)
 - [Neural Network as a Function](#neural-network-as-a-function)
 - [Activation](#activation)
 - [Cost Function as a Function](#cost-function-as-a-function)  

[Part.2: Gradient Descent](#ii.-gradient-descent)  
[Part.3: BackProp](#iii.-backprop)  

## I. Definitions & Terminology
### The Neuron
Neuron is a fundamental decision making machine. It uses weighted inputs & some bias to make these "decisions".  
Weights impact how important each input is, while Bias impacts how easy it is to "[fire](#activation)" a neuron. (More on this soon)
<img src="/images/site/twitter_handle_blue.JPG" width="250" alt="Neuron with inputs, weights" /> 

This is the simplest neuron we can imagine & it's called **Perceptron**.  
For more complex & subtle decision making, we need a **network** of these pieces. 

### Learning Algorithm
Neurons are seen as fundamental decision making machine so far, but turns out they can also be seen as fundamental computational units.  
How? With the right combination of weights & biases, we can make a neuron behave like a NAND Gate, which is a Universal Gate. 
<img src="/images/site/myavatar.svg" width="250" alt="Neuron as NAND" />
Ok, so what? It means we can create any elaborate logic, just by using a circuit NAND Gate & thus just by using a simple network of neurons!
> "It's difficult to envision what you can create given powerful primitives. Almost everything you see on a screen sits on top of NAND gates;"  
> "Just like you can, technically speaking, build any program entirely out of NAND gates, you can equally build any program out of neural networks... and nobody funds NAND gates."  
-[@patio11](https://twitter.com/patio11/status/1334519288284258305?s=20)

But it's extremely difficult to keep track of so many weights & biases of a circuit of neurons for every use case. That's where **learning algorithms** help as they can automatically learn the right combination of weights & biases for a given task. 

<!-- <img src="/images/site/myavatar.svg" width="250" alt="" /> -->

### The Sigmoid Neuron
One problem with network of Perceptrons is, even with a network of those, they're still binary.  
What makes "learning" possible in neural networks is that - *small changes in weights & biases causes small changes in output* .   
<img src="/images/site/myavatar.svg" width="250" alt="neuural network + small changes" />

This is not possible with Perceptron as it flips suddenly after inputs cross a certain point. What we need is a smoother transition.  
Enter Sigmoid. `σ()`

<img src="/images/site/myavatar.svg" width="250" alt="sigmoid" />

We can even mathematically tweak the behavior of Sigmoid neuron to increase the rate at which `σ(x)` increase for inputs close to 0 by adding a constant `C`. 
<img src="/images/site/myavatar.svg" width="250" alt="sigmoid changes as C changes" />

Simply put, as `C`↑ the function comes closer to Perceptron / Step Function


### Neural Network arrangement
 
<img src="/images/site/myavatar.svg" width="250" alt="network with input, hidden & output layers" />

### Neural Network as a Function
- Input: 
- Parameters:
- Output:

### Activation
 - We call a neuron active when it's "lit up!"
 - Activations of input layer depends on how input is encoded & fed into the network  
    Ex: In case of images, it's pixel values. 
 - Activations of output layer are effectively, the predictions/choices the network is making  
    Ex: In case of a classifier network, it's the class the network choses to put input into (cat or dog)
 - Activations of inner layers: 

 - Activations of one layer decides activations in the next layer. How?
    - Find Weighted sum of all activations of previous layer 
    - 'Squish' the sum into a range between 0 & 1. 
      




### Cost Function as a Function
- Input:
- Parameters:
- Output:

## II. Gradient Descent
What's the use of Gradient Descent ? 
To find minima of cost function. 

wait, what's a cost function?
It gives us a number that shows how lame the model is. higher the cost, lamer the model
Simple calculus of finding points where ∂C/∂w = 0 won't work?  
No, definitely not for function with potentially millions of parameters.

How does Gradient Descent work ? 
Start at a random point & figure out next step that will lower the functions value. 

Ok, but how?
``
1. Find slope at a random initial point. 
2. Move to the left if slope is +ve. Move to the right if slope is -ve. 
3. Keep moving till we reach a point of 0 slope. That's our minima! 
``
Pro Tip: If we can move with step sizes proportional to the slope, we won't re-bounce off the minima. 

Sounds simple, but what's the catch? 
The minima we're gonna reach is Local. It depends on the random initial point you started with. 


- All you need to remember is there exists a way to know what the downhill direction is & how steep it is. 
    - tangent at a point
    <img>
    - when there are 2 variables
    <img>
    - scale it to n variables
    <img>


## III. BackProp

### Links
 - 3Blue1Brown series on Neural Networks
 - Michael Nielson's NNDL e-book